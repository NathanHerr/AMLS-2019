{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from skimage.feature import local_binary_pattern # Local Binary Pattern function\n",
    "from skimage import io\n",
    "from scipy.stats import itemfreq # To calculate a normalized histogram \n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "from natsort import natsorted, ns\n",
    "import cvutils\n",
    "import csvs\n",
    "import os\n",
    "import dlib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import progressbar\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of image names and corresponding gender classifications\n",
    "image_dic = pandas.read_excel('../Datasets/labels_A.xlsx')\n",
    "image_dic = image_dic[['img_name.jpg', 'gender']] # Choose columns which are of importance\n",
    "df = pandas.DataFrame(image_dic)\n",
    "image_dic_list = df.values.tolist()\n",
    "\n",
    "# Create naturally sorted list of file paths for each image\n",
    "file_paths = glob.glob (\"../Datasets/img_A/*.jpg\") #find all paths which match the given path\n",
    "file_paths = natsorted(file_paths) #sort the list of file names such that the image list will be in the correct order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just cropping - seems to have been aligned already\n",
    "def detect_faces(image):\n",
    "    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    # Run detector and get bounding boxes of the faces on image.\n",
    "    detected_faces = face_detector(image, 1)\n",
    "    face_frames = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "    return face_frames\n",
    "\n",
    "# Set up progress bar\n",
    "max_val = len(file_paths)\n",
    "pb = display.ProgressBar(max_val)\n",
    "pb.display()\n",
    "i = 0\n",
    "\n",
    "# initiate lists and counter\n",
    "faces = []\n",
    "imgs_used = []\n",
    "imgs_not_used = []\n",
    "face_counter = 0\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Load image\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #read the image as grayscale\n",
    "    # Detect faces\n",
    "    detected_faces = detect_faces(image)\n",
    "    # Find images where only one face is detected\n",
    "    if len(detected_faces) == 1:\n",
    "        # Crop faces\n",
    "        for n, face_rect in enumerate(detected_faces):\n",
    "            face = Image.fromarray(image).crop(face_rect)\n",
    "            face_counter += 1\n",
    "            faces.append(face)\n",
    "        imgs_used.append(file_path)\n",
    "    else:\n",
    "        imgs_not_used.append(file_path)\n",
    "    # Update progress bar\n",
    "    pb.progress = i + 1\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imgs_not_used))\n",
    "print(type(faces[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating image label dictionary and path list\n",
    "\n",
    "print(\"Original path list length:\")\n",
    "print(len(file_paths))\n",
    "print(\"Number of images used:\")\n",
    "print(len(imgs_used))\n",
    "print(\"Number of images not used:\")\n",
    "print(len(imgs_not_used))\n",
    "\n",
    "# Removing unsued image paths from original image path list\n",
    "for img_not_used in imgs_not_used:\n",
    "    try:\n",
    "        file_paths.remove(img_not_used)\n",
    "    except:\n",
    "       continue \n",
    "    \n",
    "print(\"New path list length:\")\n",
    "print(len(file_paths))\n",
    "\n",
    "# Removing name and label pairs which are not used from original image dictionary\n",
    "for img_not_used in imgs_not_used:\n",
    "    i = 0\n",
    "    for image in image_dic_list:\n",
    "        if image[0] == os.path.basename(img_not_used):\n",
    "            del image_dic_list[i]\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_dic_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving new image dictionary as CSV file\n",
    "df = pandas.DataFrame(image_dic_list, columns= ['img_name.jpg', 'gender'])\n",
    "export_csv = df.to_excel (r'../Datasets/labels_A_updated_2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cropped and gray-scale images to new directory for later use\n",
    "\n",
    "new_directory = '../Datasets/cropped2_img_A/'\n",
    "print(\"writing faces to disk...\")\n",
    "if os.path.exists(new_directory):\n",
    "    print(\"Path already exists\")\n",
    "else:\n",
    "    print('creating output directory: %s'%(new_directory))\n",
    "    os.mkdir(new_directory)\n",
    "    i = 0\n",
    "    for face in faces:\n",
    "        basewidth = 256\n",
    "        wpercent = (basewidth / float(face.size[0]))\n",
    "        hsize = int((float(face.size[1]) * float(wpercent)))\n",
    "        face = face.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "        face = face.crop(( 0, hsize - 255 , basewidth , hsize))\n",
    "        face.save(''.join([new_directory,os.path.basename(imgs_used[i])]))\n",
    "        i += 1\n",
    "    print(\"wrote %d faces out of %d\"%(len(faces), max_val))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create updated list of image names and corresponding gender classifications\n",
    "image_dic = pandas.read_excel('../Datasets/labels_A_updated.xlsx')\n",
    "image_dic = image_dic[['img_name.jpg', 'gender']] # Choose columns which are of importance\n",
    "df = pandas.DataFrame(image_dic)\n",
    "image_dic_list = df.values.tolist()\n",
    "\n",
    "# Create naturally sorted list of file paths for each cropped gray scale image image\n",
    "updated_file_paths = glob.glob (\"../Datasets/cropped2_img_A/*.jpg\") #find all paths which match the given path\n",
    "updated_file_paths = natsorted(updated_file_paths) #sort the list of file names such that the image list will be in the correct order\n",
    "\n",
    "print(updated_file_paths[:10])\n",
    "print(image_dic_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 255\n",
    "changed = 0\n",
    "for file in updated_file_paths:\n",
    "    image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    if image.shape != (255,256):\n",
    "        print(false)\n",
    "print(changed)\n",
    "image = cv2.imread(updated_file_paths[6], cv2.IMREAD_GRAYSCALE)\n",
    "print(image.shape == (255,256))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align cropped images\n",
    "\n",
    "def detect_faces_for_alignement(image):\n",
    "    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    # Run detector and get bounding boxes of the faces on image.\n",
    "    detected_faces = face_detector(image, 1)\n",
    "    face_frames = [(x.left(), x.top(), x.right(), x.bottom()) for x in detected_faces]\n",
    "    return detected_faces\n",
    "\n",
    "faces = []\n",
    "imgs_used_2 = []\n",
    "imgs_not_used_2 = []\n",
    "face_counter = 0\n",
    "width = 256\n",
    "height = 255\n",
    "for file_path in updated_file_paths:    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #read the image as grayscale\n",
    "    # Detect & predict faces\n",
    "    detected_faces = detect_faces_for_alignement(image)\n",
    "    if len(detected_faces) == 1:\n",
    "        # align faces\n",
    "        predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "        shape = predictor(image, detected_faces[0]) # get facial features\n",
    "        shape = np.array([(shape.part(j).x, shape.part(j).y) for j in range(shape.num_parts)])\n",
    "\n",
    "        # center and scale face around mid point between eyes\n",
    "        center_eyes = shape[27].astype(np.int)\n",
    "        eyes_d = np.linalg.norm(shape[36]-shape[45])\n",
    "        face_size_x = int(eyes_d * 2.)\n",
    "        #if face_size_x < 50: continue\n",
    "\n",
    "        # rotate to normalized angle\n",
    "        d = (shape[45] - shape[36]) / eyes_d # normalized eyes-differnce vector (direction)\n",
    "        a = np.rad2deg(np.arctan2(d[1],d[0])) # angle\n",
    "        scale_factor = float(256) / float(face_size_x * 2.) # scale to fit in output_size\n",
    "        # rotation (around center_eyes) + scale transform\n",
    "        M = np.append(cv2.getRotationMatrix2D((center_eyes[0], center_eyes[1]),a,scale_factor),[[0,0,1]], axis=0)\n",
    "        # apply shift from center_eyes to middle of output_size \n",
    "        M1 = np.array([[1.,0.,-center_eyes[0]+width/2.],\n",
    "                       [0.,1.,-center_eyes[1]+height/2.],\n",
    "                       [0,0,1.]])\n",
    "        # concatenate transforms (rotation-scale + translation)\n",
    "        M = M1.dot(M)[:2]\n",
    "        # warp\n",
    "        face = cv2.warpAffine(image, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "        #face = Image.fromarray(image_aligned)\n",
    "        #face = face.resize((width,height), Image.ANTIALIAS)\n",
    "        face = cv2.resize(face,(width,height))\n",
    "        faces.append(face)\n",
    "        face_counter += 1\n",
    "        print(file_path)\n",
    "        imgs_used_2.append(file_path)\n",
    "    else:\n",
    "        imgs_not_used_2.append(file_path)        \n",
    "print(face_counter)\n",
    "faces = np.asarray(faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imgs_used_2))\n",
    "print(imgs_not_used_2[:10])\n",
    "print(faces[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving aligned gray and crapped\n",
    "new_directory = '../Datasets/again_aligned_cropped_img_A/'\n",
    "print(\"writing faces to disk...\")\n",
    "if os.path.exists(new_directory):\n",
    "    print(\"Path already exists\")\n",
    "else:\n",
    "    print('creating output directory: %s'%(new_directory))\n",
    "    os.mkdir(new_directory)\n",
    "    i = 0\n",
    "    for face in faces:\n",
    "        face = Image.fromarray(face).crop(( face.shape[1]/4, face.shape[0]/4 , face.shape[1]*(3/4) , face.shape[0]*(3/4)))\n",
    "        #face = face.crop(( 0, hsize - 255 , basewidth , hsize))\n",
    "        #cv2.imwrite(''.join([new_directory,os.path.basename(imgs_used_2[i])]), face)\n",
    "        face.save(''.join([new_directory,os.path.basename(imgs_used_2[i])]))\n",
    "        i += 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_not_used in imgs_not_used_2:\n",
    "    i = 0\n",
    "    for image in image_dic_list:\n",
    "        if image[0] == os.path.basename(img_not_used):\n",
    "            del image_dic_list[i]\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "# Saving new image dictionary as CSV file\n",
    "df = pandas.DataFrame(image_dic_list, columns= ['img_name.jpg', 'gender'])\n",
    "export_csv = df.to_excel (r'../Datasets/again_aligned_labels_A_updated_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create updated list of image names and corresponding gender classifications\n",
    "image_dic = pandas.read_excel('../Datasets/labels_A_updated_2.xlsx')\n",
    "image_dic = image_dic[['img_name.jpg', 'gender']] # Choose columns which are of importance\n",
    "df = pandas.DataFrame(image_dic)\n",
    "image_dic_list = df.values.tolist()\n",
    "\n",
    "# Create naturally sorted list of file paths for each cropped gray scale image image\n",
    "updated_file_paths = glob.glob (\"../Datasets/cropped2_img_A/*.jpg\") #find all paths which match the given path\n",
    "updated_file_paths = natsorted(updated_file_paths) #sort the list of file names such that the image list will be in the correct order\n",
    "\n",
    "print(updated_file_paths[:10])\n",
    "print(len(updated_file_paths))\n",
    "print(image_dic_list[:10])\n",
    "print(len(image_dic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "images = []\n",
    "y = []\n",
    "i = 0\n",
    "for file_path in updated_file_paths:\n",
    "    img = kimage.load_img(file_path, target_size=(258,256,1), grayscale = True) #read the image as grayscale\n",
    "    img = kimage.img_to_array(img)\n",
    "    img = img/255\n",
    "    images.append(img)\n",
    "    y.append(image_dic_list[i][1]) # Append class label\n",
    "    i += 1\n",
    "\n",
    "X = np.array(images)\n",
    "\n",
    "i = 0\n",
    "for e in y:\n",
    "    if e == -1:\n",
    "        y[i] = 0\n",
    "    i += 1\n",
    "        \n",
    "print(y[:10])\n",
    "y = to_categorical(y)\n",
    "print(y[:10])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(258, 256,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LBP on updated grayscale cropped images\n",
    "\n",
    "images_list = []\n",
    "image_path = []\n",
    "image_inputs = []\n",
    "image_labels = []\n",
    "\n",
    "i = 0\n",
    "for file_path in updated_file_paths:\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #read the image as grayscale\n",
    "    radius = 3    \n",
    "    no_points = 8*radius  # Number of points to be considered as neighbourers\n",
    "    eps=1e-7\n",
    "    lbp = local_binary_pattern(image, no_points, radius, method='uniform') # Uniform LBP is used\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, no_points + 3), range=(0, no_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    hist_norm = hist\n",
    "    #hist = itemfreq(lbp.ravel()) # Calculate the histogram -> why do we ravel\n",
    "    #hist_norm = hist[:, 1]/sum(hist[:, 1]) # Normalize the histogram\n",
    "    images_list.append(image)    \n",
    "    image_path.append(file_path)# Append image path    \n",
    "    image_inputs.append(hist_norm)# Append histogram    \n",
    "    image_labels.append(image_dic_list[i][1]) # Append class label\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "image_path = []\n",
    "image_inputs = []\n",
    "image_labels = []\n",
    "\n",
    "i = 0\n",
    "for file_path in updated_file_paths:\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #read the image as grayscale\n",
    "    features = np.reshape(image, (255*256))\n",
    "    image_inputs.append(features)# Append    \n",
    "    image_labels.append(image_dic_list[i][1]) # Append class label\n",
    "    i = i+1\n",
    "image_inputs = normalize(image_inputs, axis=1, norm='l1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_inputs[:1])\n",
    "print(image_labels[:10])\n",
    "np.arange(11, 17, 0.5).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_inputs,image_labels, test_size=0.5)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': np.arange(9,10,0.1).tolist(),\n",
    "                     'C': np.arange(1400,1420,5).tolist(), 'tol': [1e-5,1e-4,1e-3, 1e-2, 1e-1]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing(75% training and 25% testing data)\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(image_inputs,image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(xTest)\n",
    "\n",
    "print(accuracy_score(yTest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1405\n",
    "gamma = 9.7\n",
    "tol = 0.01\n",
    "svc = SVC(C=c, kernel='rbf', gamma = gamma, tol = tol, probability = True)\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=50, base_estimator = svc, learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(xTest)\n",
    "\n",
    "print(accuracy_score(yTest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "model = gnb.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(xTest)\n",
    "print(accuracy_score(yTest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=50, base_estimator = gnb, learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(xTest)\n",
    "\n",
    "print(accuracy_score(yTest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(xTrain, yTrain)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(xTest, yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "model = xgb_clf.fit(np.asarray(xTrain), np.asarray(yTrain))\n",
    "score = model.score(xTest, yTest)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1405\n",
    "gamma = 9.7\n",
    "tol = 0.01\n",
    "clf = SVC(C=c, kernel='rbf', gamma = gamma, tol = tol)\n",
    "clf.fit(xTrain, yTrain)\n",
    "yPredict = clf.predict(xTest)\n",
    "print(accuracy_score(yTest,yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to understand the structure\n",
    "#images_array = np.array(images_list)\n",
    "#print(images_array.shape) #(number of images x height x width x number of channels) => note that since it is grayscale, there is only 1 channel\n",
    "#print(np.array(image_path).shape)\n",
    "#print(np.array(image_inputs).shape)\n",
    "#print(np.array(image_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allignment Cell attempt 1\n",
    "'''def face_data_normalizer(input_unaligned, \n",
    "                         output_aligned, \n",
    "                         output_size= 256, \n",
    "                         align_faces_= True, \n",
    "                         limit_num_faces_= None,\n",
    "                         limit_num_files_= None,\n",
    "                         remove_outliers_ = False):\n",
    "    \n",
    "    def write_faces_to_disk(new_directory, faces):\n",
    "        print(\"writing faces to disk...\")\n",
    "        if os.path.exists(new_directory):\n",
    "            shutil.rmtree(new_directory)\n",
    "        print('creating output new_directory: %s'%(new_directory))\n",
    "        os.mkdir(new_directory)\n",
    "        for i in range(faces.shape[0]):\n",
    "            cv2.imwrite(''.join([new_directory,\"%03d.jpg\"%i]),faces[i,:,:,::-1])\n",
    "        print(\"wrote %d faces\"%(faces.shape[0]))\n",
    "     \n",
    "    if input_unaligned[-1] != '/':\n",
    "        input_unaligned += '/'\n",
    "    if output_aligned[-1] != '/':\n",
    "        output_aligned += '/'\n",
    " \n",
    "    faces = []\n",
    " \n",
    "    if os.path.exists(output_aligned):\n",
    "        print('data already preprocessed? loading preprocessed files...')\n",
    "        #for img_idx,img_file in enumerate(os.listdir(output_aligned)):\n",
    "            # load the input image, resize it, and convert it to grayscale\n",
    "        #    image = cv2.imread(''.join([output_aligned,img_file]))\n",
    "         #   if image is None: continue\n",
    "         #   image = image[:,:,::-1] #BGR to RGB\n",
    "         #   faces.append(np.expand_dims(image,0))\n",
    "        #faces = np.asarray(faces)\n",
    "        #print('loaded %d preprocessed images'%(faces.shape[0]))\n",
    "        #if remove_outliers_:\n",
    "        #    faces,num_outliers = remove_outliers(faces)\n",
    "        #write_faces_to_disk(output_aligned,faces)\n",
    "        return faces\n",
    "     \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "         \n",
    "    max_val = len(os.listdir(input_unaligned)) if limit_num_files_ is None else limit_num_files_\n",
    "    print(max_val)\n",
    "    pb = display.ProgressBar(max_val)\n",
    "    pb.display()\n",
    "         \n",
    "    face_counter = 0\n",
    "    for img_idx,img_file in enumerate(os.listdir(input_unaligned)):\n",
    "        # load the input image, resize it, and convert it to grayscale\n",
    "        image = cv2.imread(''.join([input_unaligned,img_file]))\n",
    " \n",
    "        #if image is None:\n",
    "        #    continue\n",
    " \n",
    "        image = image[:,:,::-1] #BGR to RGB\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        # detect faces in the grayscale image\n",
    "        rects = detector(gray, 1)\n",
    "        #print(len(rects))\n",
    " \n",
    "        if len(rects) > 0:\n",
    "            # loop over the face detections\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                if align_faces_:\n",
    "                    #print(\"Aligning\")\n",
    "                    ######### Align with facial features detector #########\n",
    " \n",
    "                    shape = predictor(gray, rect) # get facial features\n",
    "                    shape = np.array([(shape.part(j).x, shape.part(j).y) for j in range(shape.num_parts)])\n",
    " \n",
    "                    # center and scale face around mid point between eyes\n",
    "                    center_eyes = shape[27].astype(np.int)\n",
    "                    eyes_d = np.linalg.norm(shape[36]-shape[45])\n",
    "                    face_size_x = int(eyes_d * 2.)\n",
    "                    #if face_size_x < 50: continue\n",
    " \n",
    "                    # rotate to normalized angle\n",
    "                    d = (shape[45] - shape[36]) / eyes_d # normalized eyes-differnce vector (direction)\n",
    "                    a = np.rad2deg(np.arctan2(d[1],d[0])) # angle\n",
    "                    scale_factor = float(output_size) / float(face_size_x * 2.) # scale to fit in output_size\n",
    "                    # rotation (around center_eyes) + scale transform\n",
    "                    M = np.append(cv2.getRotationMatrix2D((center_eyes[0], center_eyes[1]),a,scale_factor),[[0,0,1]], axis=0)\n",
    "                    # apply shift from center_eyes to middle of output_size \n",
    "                    M1 = np.array([[1.,0.,-center_eyes[0]+output_size/2.],\n",
    "                                   [0.,1.,-center_eyes[1]+output_size/2.],\n",
    "                                   [0,0,1.]])\n",
    "                    # concatenate transforms (rotation-scale + translation)\n",
    "                    M = M1.dot(M)[:2]\n",
    "                    # warp\n",
    "                    face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    #try:\n",
    "                    #   face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    #except:\n",
    "                    #    continue\n",
    "                    face_counter += 1\n",
    "                    face = cv2.resize(face,(output_size,output_size))\n",
    "                    faces.append(face)\n",
    "                else:\n",
    "                    ######### \"No align\" with just the detector #########\n",
    "                    #print(\"Not Aligning\")\n",
    "                    #if rect.width() < 50: continue\n",
    "                     \n",
    "                    # find scale factor\n",
    "                    scale_factor = float(output_size) / float(rect.width() * 2.) # scale to fit in output_size\n",
    "                     \n",
    "                    # scale around the center of the face (shift a bit for the approximate y-position of the eyes)\n",
    "                    M = np.append(cv2.getRotationMatrix2D((rect.center().x,rect.center().y-rect.height()/6.),0,scale_factor),[[0,0,1]], axis=0)\n",
    "                    # apply shift from center_eyes to middle of output_size \n",
    "                    M1 = np.array([[1.,0.,-rect.center().x+output_size/2.],\n",
    "                                   [0.,1.,-rect.center().y+output_size/2.+rect.height()/6.],\n",
    "                                   [0,0,1.]])\n",
    "                    # concatenate transforms (rotation-scale + translation)\n",
    "                    M = M1.dot(M)[:2]\n",
    "                    face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    #try:\n",
    "                    #    face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    #except:\n",
    "                    #    continue\n",
    "                    face_counter += 1\n",
    " \n",
    "                    faces.append(face)\n",
    "                 \n",
    "        pb.progress = img_idx+1\n",
    "        if face_counter > 50:\n",
    "            break\n",
    "        if limit_num_faces_ is not None and faces.shape[0] > limit_num_faces_:\n",
    "            break\n",
    "        if limit_num_files_ is not None and img_idx >= limit_num_files_:\n",
    "            break\n",
    "    print(type(faces))\n",
    "    print(type(faces[0]))\n",
    "    print(len(faces[0]))\n",
    "    faces = np.asarray(faces)\n",
    "    print(type(faces))\n",
    "    print(type(faces[0]))\n",
    "    print(len(faces[0]))\n",
    "    print(faces.shape[0])\n",
    "\n",
    "    write_faces_to_disk(output_aligned,faces)\n",
    "     \n",
    "    return faces\n",
    "    \n",
    "faces_align = face_data_normalizer('../Datasets/img_A/',\n",
    "                                   '../Datasets/aligned_img_A/', \n",
    "                                   align_faces_=True, \n",
    "                                   remove_outliers_= False,\n",
    "                                   limit_num_faces_= None,\n",
    "                                   limit_num_files_= None,\n",
    "                                   output_size=256);\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align & cropping attempt 2 Cropping Cell\n",
    "'''\n",
    "def detect_faces(image):\n",
    "\n",
    "    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # Run detector and get bounding boxes of the faces on image.\n",
    "    detected_faces = face_detector(image, 1)\n",
    "    face_frames = [(x.left(), x.top(), x.right(), x.bottom()) for x in detected_faces]\n",
    "    return detected_faces, face_frames\n",
    "\n",
    "faces = []\n",
    "face_counter = 0\n",
    "output_size = 256\n",
    "for file_path in file_paths:\n",
    "    \n",
    "    # Load image\n",
    "    image = io.imread(file_path)\n",
    "    image = image[:,:,::-1] #BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #read the image as grayscale\n",
    "    # Detect & predict faces\n",
    "    detected_faces, face_frames = detect_faces(image)\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    shape = predictor(image, detected_faces[0]) # get facial features\n",
    "    shape = np.array([(shape.part(j).x, shape.part(j).y) for j in range(shape.num_parts)])\n",
    "\n",
    "    # center and scale face around mid point between eyes\n",
    "    center_eyes = shape[27].astype(np.int)\n",
    "    eyes_d = np.linalg.norm(shape[36]-shape[45])\n",
    "    face_size_x = int(eyes_d * 2.)\n",
    "    #if face_size_x < 50: continue\n",
    "\n",
    "    # rotate to normalized angle\n",
    "    d = (shape[45] - shape[36]) / eyes_d # normalized eyes-differnce vector (direction)\n",
    "    a = np.rad2deg(np.arctan2(d[1],d[0])) # angle\n",
    "    scale_factor = float(output_size) / float(face_size_x * 2.) # scale to fit in output_size\n",
    "    # rotation (around center_eyes) + scale transform\n",
    "    M = np.append(cv2.getRotationMatrix2D((center_eyes[0], center_eyes[1]),a,scale_factor),[[0,0,1]], axis=0)\n",
    "    # apply shift from center_eyes to middle of output_size \n",
    "    M1 = np.array([[1.,0.,-center_eyes[0]+output_size/2.],\n",
    "                   [0.,1.,-center_eyes[1]+output_size/2.],\n",
    "                   [0,0,1.]])\n",
    "    # concatenate transforms (rotation-scale + translation)\n",
    "    M = M1.dot(M)[:2]\n",
    "    # warp\n",
    "    image_aligned = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "    face = Image.fromarray(image_aligned).crop(face_frames[0])\n",
    "    #face = cv2.resize(face,(output_size,output_size))\n",
    "    faces.append(face)\n",
    "    face_counter += 1\n",
    "    \n",
    "print(face_counter)\n",
    "faces = np.asarray(faces)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
